---
slug: 'handar'
title: 'HandAR — Assistance à distance en réalité augmentée'
stack: ['Unity 3D', 'ARCore', 'MediaPipe', 'WebRTC']
tags: ['AR', 'Réalité augmentée', 'Assistance à distance', 'Hackathon']
category: 'XR Projects'
cover: '/images/projects/handar/cover.jpg'
gallery:
  - '/images/projects/handar/screenshot-1.jpg'
  - '/images/projects/handar/screenshot-2.jpg'
  - '/images/projects/handar/screenshot-3.jpg'
  - '/images/projects/handar/demo.mp4'
links:
  - label: 'Présentation'
    href: 'https://www.canva.com/design/DAGYqpDN_d0/T1aLa05oVmpebv5Yqi7myA/view?utm_content=DAGYqpDN_d0&utm_campaign=designshare&utm_medium=link&utm_source=editor'
---

## Résumé

**HandAR** est une application de **réalité augmentée (AR)** visant à améliorer l’**assistance à distance** en rendant les interactions plus précises et intuitives.  
Développée lors du **HackTheSixth Hackathon 2024 à Toronto**, l’application permet une visualisation claire des gestes et objets, ainsi que l’ajout d’annotations en temps réel pour guider efficacement l’utilisateur.

---

## Contexte et Objectifs

Les systèmes traditionnels d’assistance à distance présentent plusieurs limites :  

- Visualisation insuffisante des mains et des objets.  
- Absence de repères et d’annotations en temps réel.  
- Difficulté pour les personnes sourdes ou malentendantes d’obtenir un soutien fiable et rapide.  

L’objectif de HandAR était de **réinventer l’assistance à distance** en utilisant la réalité augmentée pour rendre la communication plus claire et intuitive.

---

## Fonctionnalités principales

- **Réalité augmentée** : superposition d’éléments virtuels sur le monde réel pour une visualisation précise des objets et actions.  

![Screenshot HandAR](/images/projects/handar/screenshot-1.jpg)

- **Appels vidéo intégrés** : communication visuelle en temps réel entre l’utilisateur et l’assistance.  
- **Suivi des mains en temps réel** : détection et visualisation précise des gestes de l’utilisateur grâce à MediaPipe.  

![Screenshot HandAR](/images/projects/handar/screenshot-3.jpg)

Video de la feature -> https://drive.google.com/file/d/1LWapOC03IS3d-0poyq_-svzfWeMbjEao/view?usp=sharing

- **Annotations en direct** : ajout de flèches, points d’intérêt et repères directement sur l’écran pour guider l’utilisateur.  

![Screenshot HandAR](/images/projects/handar/screenshot-2.jpg)

Video de la feature -> https://drive.google.com/file/d/1cyBDKNZY_oACwlZZazF0B8AWKcapji0Q/view?usp=sharing


---

## Implémentation

- **Moteur** : Unity 3D  
- **AR** : ARCore  
- **Détection de gestes** : MediaPipe  
- **Communication en temps réel** : WebRTC  

Les principaux défis techniques comprenaient :  
- Synchronisation des flux vidéo et AR en temps réel.  
- Détection et rendu précis des mains dans différents environnements.  
- Intégration fluide des annotations interactives sur la vidéo et l’AR.

---


## Perspectives

- Étendre le support aux **tablettes et casques AR** pour plus d’immersion.  
- Ajouter des **scénarios spécifiques** pour les formations techniques ou médicales.  
- Améliorer la **précision et réactivité du suivi des mains** dans des environnements complexes.  
- Intégrer un **système de collaboration multi-utilisateurs** pour les équipes à distance.

---

## Remerciements

Ce projet a été développé lors du **HackTheSixth Hackathon 2024 à Toronto, Canada**, en collaboration avec une équipe multidisciplinaire.
